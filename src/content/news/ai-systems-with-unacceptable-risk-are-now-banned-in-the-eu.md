---
title: "AI systems with 'unacceptable risk' are now banned in the EU"
subtitle: "An insightful look into 'AI systems with 'unacceptable risk' are now banned in the EU'"
description: "The European Union has enacted a landmark regulatory framework, the AI Act, which officially prohibits AI systems deemed to pose an \"unacceptable risk\" starting February 2, 2025. This robust legislation categorizes AI into four risk levels, with the highest tier facing outright bans to protect citizens from potential harms. Proscribed applications include AI tools for social scoring, subliminal manipulation, and biometric data collection in public spaces for law enforcement. Companies violating these rules could face hefty fines reaching up to €35 million or 7% of their annual revenue. While over 100 companies have already pledged early compliance under the EU AI Pact, major tech firms like Meta and Apple remain cautious, as industry leaders call for clearer guidelines to navigate overlapping legal frameworks such as"
publishedOn: 2025-04-07
updatedOn: 2025-02-06
mainImage: "https://cdn.prod.website-files.com/672916ba596e9ad764eea6e4/67a23e488917eebc88fcb309_tmpnti2lnsu.png"
thumbnail: ""
altTextThumbnail: ""
altTextMainImage: "A visually stunning main image for the article: AI systems with 'unacceptable risk' are now banned in the EU"
source: "techcrunch.com"
newsDate: 2025-02-04
draft: false
archived: false
---

<h2>EU Enforces Ban on 'Unacceptable Risk' AI Systems</h2>

<h3>Overview of the EU AI Act</h3>
As of February 2, 2025, the European Union has implemented its AI Act, marking a significant step in regulating artificial intelligence across the bloc. This comprehensive framework, approved by the European Parliament last March after extensive deliberations, empowers regulators to prohibit AI systems deemed to pose "unacceptable risks" or potential harm.

<h3>Risk Classification and Compliance</h3>
The AI Act classifies AI applications into four risk categories:

1. **Minimal risk**: Applications like email spam filters, which require no regulatory oversight.
2. **Limited risk**: Systems such as customer service chatbots, subject to light-touch oversight.
3. **High risk**: Examples include AI used in healthcare recommendations, needing heavy regulatory scrutiny.
4. **Unacceptable risk**: Prohibited applications include systems for social scoring, manipulative decision-making processes, and prediction of criminal behavior based on appearance.

As February 2 marks the first compliance deadline, organizations must ensure they align with these classifications. Companies violating the Act by employing banned systems face substantial fines of up to €35 million or 7% of their previous fiscal year's revenue, whichever is greater.

<h3>Implementation and Enforcement</h3>
While the February 2 deadline signifies the start of compliance, enforcement will intensify in August when competent authorities are expected to be in place. Organizations should anticipate rigorous enforcement of the Act's provisions by this time.

<h3>Preliminary Industry Responses</h3>
Prior to this mandate, over 100 companies, including technology giants like Amazon, Google, and OpenAI, committed to the EU AI Pact. This pledge signifies their willingness to adhere to the AI Act principles ahead of enforcement. Notably, companies such as Meta and Apple did not participate in this voluntary accord.

<h4>Industry Concerns and Exemptions</h4>
The Act's strictures are not without exceptions. For instance, law enforcement may utilize biometric data in public areas under specific circumstances, such as locating abducted individuals. Systems designed for workplace or educational environments with a "medical or safety" justification are also exempt.

The European Commission plans to clarify operational guidelines later this year, refining how these regulations will co-exist with other legal frameworks like the GDPR, NIS2, and DORA. Achieving clarity on these intersecting laws is essential for organizations navigating the complexities of AI regulation.

<h3>Conclusion</h3>
The EU AI Act represents a pivotal move in the global effort to regulate artificial intelligence, setting a benchmark for assessing and mitigating the risks associated with various AI applications. As the Act's stipulations take effect, companies operating in the EU must prioritize compliance to avert significant penalties and foster ethical AI deployment.